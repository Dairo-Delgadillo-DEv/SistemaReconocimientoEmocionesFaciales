# Sistema de Reconocimiento de Emociones Faciales
## An√°lisis Completo del Proyecto

---

## üìã Descripci√≥n General

Este proyecto es un **sistema de reconocimiento de emociones faciales en tiempo real** que utiliza visi√≥n por computadora y an√°lisis de malla facial (face mesh) para detectar y cuantificar 6 emociones b√°sicas:

- üòä **Felicidad (Happy)**
- üò¢ **Tristeza (Sad)**
- üò† **Enojo (Angry)**
- üò® **Miedo (Fear)**
- üò≤ **Sorpresa (Surprise)**
- ü§¢ **Disgusto (Disgust)**

El sistema procesa video en tiempo real desde una c√°mara web, detecta rostros, extrae caracter√≠sticas faciales y calcula puntuaciones para cada emoci√≥n bas√°ndose en la posici√≥n y movimiento de elementos faciales clave.

---

## üèóÔ∏è Arquitectura del Proyecto

### Estructura de Carpetas

```
emotion_processor/
‚îú‚îÄ‚îÄ face_mesh/                    # Detecci√≥n y extracci√≥n de malla facial
‚îÇ   ‚îî‚îÄ‚îÄ face_mesh_processor.py   # Usa MediaPipe para detectar 468 puntos faciales
‚îÇ
‚îú‚îÄ‚îÄ data_processing/              # Procesamiento de caracter√≠sticas faciales
‚îÇ   ‚îú‚îÄ‚îÄ eyebrows/                # An√°lisis de cejas
‚îÇ   ‚îú‚îÄ‚îÄ eyes/                    # An√°lisis de ojos
‚îÇ   ‚îú‚îÄ‚îÄ nose/                    # An√°lisis de nariz
‚îÇ   ‚îú‚îÄ‚îÄ mouth/                   # An√°lisis de boca
‚îÇ   ‚îî‚îÄ‚îÄ main.py                  # Coordinador de procesamiento
‚îÇ
‚îú‚îÄ‚îÄ emotions_recognition/         # Reconocimiento de emociones
‚îÇ   ‚îú‚îÄ‚îÄ emotions/                # Algoritmos de puntuaci√≥n por emoci√≥n
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ happy_score.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sad_score.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ angry_score.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ fear_score.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ suprise_score.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ disgust_score.py
‚îÇ   ‚îî‚îÄ‚îÄ main.py                  # Coordinador de reconocimiento
‚îÇ
‚îú‚îÄ‚îÄ emotions_visualizations/      # Visualizaci√≥n de resultados
‚îÇ   ‚îî‚îÄ‚îÄ main.py                  # Dibuja barras de emociones en pantalla
‚îÇ
‚îî‚îÄ‚îÄ main.py                      # Sistema principal integrado

examples/
‚îú‚îÄ‚îÄ camera.py                    # Clase para manejo de c√°mara
‚îî‚îÄ‚îÄ video_stream.py              # Aplicaci√≥n de ejemplo en tiempo real
```

---

## üîß Funcionamiento T√©cnico

### 1. **Captura de Video** (`examples/camera.py`)
- Captura frames de la c√°mara web usando OpenCV
- Configurable: resoluci√≥n, √≠ndice de c√°mara

### 2. **Detecci√≥n de Malla Facial** (`face_mesh/face_mesh_processor.py`)
- **MediaPipe Face Mesh**: Detecta 468 puntos de referencia en el rostro
- Extrae puntos espec√≠ficos para:
  - **Cejas**: 12 puntos (arcos y distancias)
  - **Ojos**: 18 puntos (p√°rpados y aperturas)
  - **Nariz**: 4 puntos (puente y fosas nasales)
  - **Boca**: 12 puntos (labios superior/inferior, comisuras)

### 3. **Procesamiento de Caracter√≠sticas** (`data_processing/`)
Cada regi√≥n facial se analiza independientemente:

#### Cejas (`eyebrows/`)
- Calcula curvaturas de arcos
- Mide distancias entre cejas
- Detecta: elevadas, bajadas, juntas, separadas

#### Ojos (`eyes/`)
- Analiza apertura de p√°rpados
- Calcula distancias verticales
- Detecta: abiertos, cerrados, entrecerrados

#### Nariz (`nose/`)
- Mide distancias del puente nasal
- Detecta: arrugada, neutral

#### Boca (`mouth/`)
- Analiza curvaturas de labios (polinomios)
- Mide apertura vertical
- Detecta: sonrisa, fruncida, abierta, cerrada

### 4. **Reconocimiento de Emociones** (`emotions_recognition/`)
Cada emoci√≥n tiene un algoritmo de puntuaci√≥n con **pesos espec√≠ficos**:

**Ejemplo: Felicidad (Happy)**
```python
Pesos:
- Cejas: 10%
- Ojos: 20%
- Nariz: 10%
- Boca: 60%  # La boca es m√°s importante para felicidad

Criterios:
- Cejas separadas: +50 puntos
- Ojos abiertos: +100 puntos
- Sonrisa derecha: +42 puntos
- Sonrisa izquierda: +42 puntos
```

Cada emoci√≥n tiene criterios √∫nicos basados en la **Teor√≠a de Emociones B√°sicas de Ekman**.

### 5. **Visualizaci√≥n** (`emotions_visualizations/`)
- Dibuja barras de progreso para cada emoci√≥n
- Colores √∫nicos por emoci√≥n
- Actualizaci√≥n en tiempo real

---

## üéØ Tecnolog√≠as Utilizadas

| Tecnolog√≠a | Prop√≥sito |
|------------|-----------|
| **Python 3.10** | Lenguaje base |
| **OpenCV** | Captura y procesamiento de video |
| **MediaPipe** | Detecci√≥n de malla facial (468 landmarks) |
| **NumPy** | C√°lculos matem√°ticos y arrays |
| **Matplotlib** | Visualizaciones (opcional) |

---

## üí° Aplicaci√≥n para Terapia Psicol√≥gica

### üéØ Casos de Uso Terap√©uticos

#### 1. **Monitoreo de Estado Emocional en Sesiones**
**Problema actual**: Los terapeutas dependen de la comunicaci√≥n verbal y observaci√≥n subjetiva.

**Soluci√≥n con este sistema**:
- Registro objetivo de emociones durante la sesi√≥n
- Detecci√≥n de emociones no verbalizadas
- Identificaci√≥n de patrones emocionales

**Modificaciones sugeridas**:
```python
# Agregar registro temporal de emociones
class TherapySessionRecorder:
    def __init__(self):
        self.emotion_timeline = []
        self.timestamps = []
    
    def record_emotion(self, emotions, timestamp):
        self.emotion_timeline.append(emotions)
        self.timestamps.append(timestamp)
    
    def generate_session_report(self):
        # Genera gr√°ficos de evoluci√≥n emocional
        # Identifica momentos cr√≠ticos
        # Calcula estad√≠sticas de sesi√≥n
```

#### 2. **Terapia de Regulaci√≥n Emocional**
**Aplicaci√≥n**: Pacientes con trastornos de ansiedad, depresi√≥n, TEPT

**Funcionalidad**:
- **Biofeedback visual**: El paciente ve sus emociones en tiempo real
- **Ejercicios de regulaci√≥n**: T√©cnicas de respiraci√≥n mientras monitorean su estado
- **Gamificaci√≥n**: Objetivos de mantener emociones positivas

**Modificaciones sugeridas**:
```python
# Sistema de alertas y ejercicios
class EmotionRegulationAssistant:
    def __init__(self):
        self.anxiety_threshold = 70  # Si miedo > 70%
        self.exercises = {
            'high_fear': 'Respiraci√≥n 4-7-8',
            'high_anger': 'T√©cnica de grounding 5-4-3-2-1',
            'high_sad': 'Ejercicio de gratitud'
        }
    
    def check_and_suggest(self, emotions):
        if emotions['fear'] > self.anxiety_threshold:
            return self.exercises['high_fear']
        # ... m√°s condiciones
```

#### 3. **Entrenamiento en Reconocimiento Emocional**
**Aplicaci√≥n**: Pacientes con TEA (Trastorno del Espectro Autista), alexitimia

**Funcionalidad**:
- Modo de entrenamiento con retroalimentaci√≥n
- Comparaci√≥n de expresiones propias vs. objetivo
- Biblioteca de expresiones emocionales

**Modificaciones sugeridas**:
```python
# Sistema de entrenamiento
class EmotionTrainingMode:
    def __init__(self):
        self.target_emotion = None
        self.target_score = 80
    
    def set_target(self, emotion):
        self.target_emotion = emotion
    
    def provide_feedback(self, current_emotions):
        score = current_emotions[self.target_emotion]
        if score >= self.target_score:
            return "¬°Excelente! Has logrado la expresi√≥n"
        else:
            return f"Intenta: {self.get_tips(self.target_emotion)}"
```

#### 4. **An√°lisis de Patrones a Largo Plazo**
**Aplicaci√≥n**: Seguimiento de progreso terap√©utico

**Funcionalidad**:
- Base de datos de sesiones
- Gr√°ficos de evoluci√≥n temporal
- Identificaci√≥n de triggers emocionales

**Modificaciones sugeridas**:
```python
# Sistema de an√°lisis hist√≥rico
class LongTermEmotionAnalyzer:
    def __init__(self):
        self.database = EmotionDatabase()
    
    def analyze_progress(self, patient_id, weeks=12):
        sessions = self.database.get_sessions(patient_id, weeks)
        return {
            'average_happiness': self.calc_avg('happy', sessions),
            'anxiety_reduction': self.calc_reduction('fear', sessions),
            'emotional_stability': self.calc_variance(sessions),
            'trigger_moments': self.identify_spikes(sessions)
        }
```

---

## üîÑ Modificaciones Recomendadas para Terapia

### 1. **Agregar Persistencia de Datos (Base de Datos de Sesiones)**

#### üéØ ¬øQu√© se hace?
Se crea un sistema de almacenamiento permanente para guardar todas las sesiones terap√©uticas con sus datos emocionales.

#### ü§î ¬øPor qu√© es necesario?
**Problema actual**: El sistema solo muestra emociones en tiempo real pero no guarda nada. Cuando termina la sesi√≥n, toda la informaci√≥n se pierde.

**Beneficios de agregarlo**:
- **Seguimiento a largo plazo**: Ver c√≥mo evoluciona el paciente semana tras semana
- **Evidencia objetiva**: Datos concretos para evaluar efectividad del tratamiento
- **Identificaci√≥n de patrones**: Detectar qu√© d√≠as/horarios el paciente est√° mejor o peor
- **Reportes para seguros**: Documentaci√≥n objetiva del progreso terap√©utico
- **Comparaci√≥n de sesiones**: "Hoy estuviste 30% menos ansioso que la semana pasada"

#### üîß ¬øC√≥mo se implementa?

**Crear**: `therapy_tools/session_database.py`
```python
import sqlite3
import json
from datetime import datetime

class SessionDatabase:
    """
    Base de datos para almacenar sesiones terap√©uticas.
    Usa SQLite (archivo local, no requiere servidor).
    """
    def __init__(self, db_path='therapy_sessions.db'):
        self.conn = sqlite3.connect(db_path)
        self.create_tables()
    
    def create_tables(self):
        """Crea las tablas necesarias si no existen"""
        self.conn.execute('''
            CREATE TABLE IF NOT EXISTS sessions (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                patient_id TEXT NOT NULL,           -- ID an√≥nimo del paciente
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                duration INTEGER,                    -- Duraci√≥n en segundos
                emotions_data TEXT,                  -- JSON con timeline de emociones
                notes TEXT,                          -- Notas del terapeuta
                session_type TEXT                    -- Tipo: inicial, seguimiento, etc.
            )
        ''')
        
        self.conn.execute('''
            CREATE TABLE IF NOT EXISTS emotion_snapshots (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                session_id INTEGER,
                timestamp_offset INTEGER,            -- Segundos desde inicio de sesi√≥n
                happy REAL,
                sad REAL,
                angry REAL,
                fear REAL,
                surprise REAL,
                disgust REAL,
                FOREIGN KEY (session_id) REFERENCES sessions(id)
            )
        ''')
        self.conn.commit()
    
    def start_session(self, patient_id, session_type='regular'):
        """Inicia una nueva sesi√≥n y retorna su ID"""
        cursor = self.conn.execute(
            'INSERT INTO sessions (patient_id, session_type) VALUES (?, ?)',
            (patient_id, session_type)
        )
        self.conn.commit()
        return cursor.lastrowid
    
    def save_emotion_snapshot(self, session_id, timestamp_offset, emotions):
        """
        Guarda un snapshot de emociones en un momento espec√≠fico.
        Se llama cada segundo o cada frame procesado.
        """
        self.conn.execute('''
            INSERT INTO emotion_snapshots 
            (session_id, timestamp_offset, happy, sad, angry, fear, surprise, disgust)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?)
        ''', (
            session_id, 
            timestamp_offset,
            emotions.get('happy', 0),
            emotions.get('sad', 0),
            emotions.get('angry', 0),
            emotions.get('fear', 0),
            emotions.get('surprise', 0),
            emotions.get('disgust', 0)
        ))
        self.conn.commit()
    
    def end_session(self, session_id, notes=''):
        """Finaliza la sesi√≥n y calcula su duraci√≥n"""
        cursor = self.conn.execute(
            'SELECT timestamp FROM sessions WHERE id = ?',
            (session_id,)
        )
        start_time = cursor.fetchone()[0]
        duration = (datetime.now() - datetime.fromisoformat(start_time)).seconds
        
        self.conn.execute(
            'UPDATE sessions SET duration = ?, notes = ? WHERE id = ?',
            (duration, notes, session_id)
        )
        self.conn.commit()
    
    def get_patient_sessions(self, patient_id, limit=10):
        """Obtiene las √∫ltimas N sesiones de un paciente"""
        cursor = self.conn.execute('''
            SELECT id, timestamp, duration, session_type, notes
            FROM sessions
            WHERE patient_id = ?
            ORDER BY timestamp DESC
            LIMIT ?
        ''', (patient_id, limit))
        return cursor.fetchall()
    
    def get_session_emotions(self, session_id):
        """Obtiene todos los snapshots de emociones de una sesi√≥n"""
        cursor = self.conn.execute('''
            SELECT timestamp_offset, happy, sad, angry, fear, surprise, disgust
            FROM emotion_snapshots
            WHERE session_id = ?
            ORDER BY timestamp_offset
        ''', (session_id,))
        return cursor.fetchall()
```

#### üìù ¬øC√≥mo se integra con el sistema actual?

**Modificar**: `examples/video_stream.py`
```python
from therapy_tools.session_database import SessionDatabase

class TherapyVideoStream(VideoStream):
    def __init__(self, cam, emotion_recognition_system, patient_id):
        super().__init__(cam, emotion_recognition_system)
        self.db = SessionDatabase()
        self.patient_id = patient_id
        self.session_id = None
        self.start_time = None
    
    def run(self):
        # Iniciar sesi√≥n en la base de datos
        self.session_id = self.db.start_session(self.patient_id)
        self.start_time = time.time()
        
        while True:
            ret, frame = self.camera.read()
            if ret:
                frame = self.emotion_recognition_system.frame_processing(frame)
                
                # NUEVO: Guardar emociones cada segundo
                current_time = time.time()
                if int(current_time - self.start_time) % 1 == 0:  # Cada segundo
                    emotions = self.emotion_recognition_system.emotions_recognition.last_emotions
                    timestamp_offset = int(current_time - self.start_time)
                    self.db.save_emotion_snapshot(self.session_id, timestamp_offset, emotions)
                
                cv2.imshow('Emotion Recognition', frame)
                if cv2.waitKey(5) == 27:  # ESC para salir
                    break
        
        # Finalizar sesi√≥n
        self.db.end_session(self.session_id)
        self.camera.release()
        cv2.destroyAllWindows()
```

### 2. **Dashboard de Terapeuta (Interfaz de Visualizaci√≥n)**

#### üéØ ¬øQu√© se hace?
Se crea una interfaz gr√°fica donde el terapeuta puede ver gr√°ficos, estad√≠sticas y an√°lisis de las sesiones de sus pacientes.

#### ü§î ¬øPor qu√© es necesario?
**Problema actual**: Los datos est√°n en la base de datos pero no hay forma f√°cil de visualizarlos. El terapeuta necesitar√≠a escribir c√≥digo SQL para ver la informaci√≥n.

**Beneficios de agregarlo**:
- **Visualizaci√≥n intuitiva**: Gr√°ficos de l√≠nea mostrando evoluci√≥n emocional
- **Ahorro de tiempo**: Ver resumen de sesi√≥n en segundos, no minutos
- **Identificaci√≥n r√°pida de problemas**: Picos de ansiedad resaltados autom√°ticamente
- **Comparaci√≥n visual**: Ver progreso entre sesiones lado a lado
- **Reportes profesionales**: Generar PDFs para compartir con paciente o colegas
- **Toma de decisiones informada**: Datos objetivos para ajustar tratamiento

#### üîß ¬øC√≥mo se implementa?

**Crear**: `therapy_tools/therapist_dashboard.py`
```python
import matplotlib.pyplot as plt
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg
import tkinter as tk
from tkinter import ttk
import numpy as np
from datetime import datetime

class TherapistDashboard:
    """
    Dashboard visual para que el terapeuta analice sesiones.
    Usa Tkinter (interfaz gr√°fica) y Matplotlib (gr√°ficos).
    """
    def __init__(self, database):
        self.db = database
        self.window = tk.Tk()
        self.window.title("Dashboard Terap√©utico - An√°lisis de Emociones")
        self.window.geometry("1200x800")
        
        # Colores de emociones (mismo que el sistema)
        self.emotion_colors = {
            'happy': '#1B97EF',
            'sad': '#BA7704',
            'angry': '#2332DC',
            'fear': '#80258E',
            'surprise': '#B8B753',
            'disgust': '#4FA424'
        }
    
    def show_session_summary(self, session_id):
        """
        Muestra resumen completo de una sesi√≥n espec√≠fica.
        
        ¬øQu√© muestra?
        - Gr√°fico de l√≠nea temporal de todas las emociones
        - Estad√≠sticas: emoci√≥n dominante, picos, promedios
        - Momentos cr√≠ticos (cuando ansiedad/tristeza fueron altas)
        - Duraci√≥n total y fecha
        """
        # Limpiar ventana
        for widget in self.window.winfo_children():
            widget.destroy()
        
        # Obtener datos de la sesi√≥n
        emotions_data = self.db.get_session_emotions(session_id)
        
        if not emotions_data:
            tk.Label(self.window, text="No hay datos para esta sesi√≥n").pack()
            return
        
        # Preparar datos para graficar
        timestamps = [row[0] for row in emotions_data]  # Segundos desde inicio
        emotions = {
            'happy': [row[1] for row in emotions_data],
            'sad': [row[2] for row in emotions_data],
            'angry': [row[3] for row in emotions_data],
            'fear': [row[4] for row in emotions_data],
            'surprise': [row[5] for row in emotions_data],
            'disgust': [row[6] for row in emotions_data]
        }
        
        # Crear figura de Matplotlib
        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))
        
        # Gr√°fico 1: L√≠neas temporales de todas las emociones
        for emotion, values in emotions.items():
            ax1.plot(timestamps, values, 
                    label=emotion.capitalize(), 
                    color=self.emotion_colors[emotion],
                    linewidth=2)
        
        ax1.set_xlabel('Tiempo (segundos)', fontsize=12)
        ax1.set_ylabel('Intensidad (%)', fontsize=12)
        ax1.set_title('Evoluci√≥n Emocional Durante la Sesi√≥n', fontsize=14, fontweight='bold')
        ax1.legend(loc='upper right')
        ax1.grid(True, alpha=0.3)
        ax1.set_ylim(0, 100)
        
        # Gr√°fico 2: Promedios por emoci√≥n (barras)
        emotion_names = list(emotions.keys())
        emotion_avgs = [np.mean(values) for values in emotions.values()]
        colors = [self.emotion_colors[e] for e in emotion_names]
        
        ax2.bar(emotion_names, emotion_avgs, color=colors, alpha=0.7)
        ax2.set_ylabel('Intensidad Promedio (%)', fontsize=12)
        ax2.set_title('Resumen: Emociones Promedio de la Sesi√≥n', fontsize=14, fontweight='bold')
        ax2.set_ylim(0, 100)
        
        # Agregar valores sobre las barras
        for i, v in enumerate(emotion_avgs):
            ax2.text(i, v + 2, f'{v:.1f}%', ha='center', fontweight='bold')
        
        plt.tight_layout()
        
        # Integrar gr√°fico en Tkinter
        canvas = FigureCanvasTkAgg(fig, master=self.window)
        canvas.draw()
        canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True)
        
        # Panel de estad√≠sticas
        stats_frame = tk.Frame(self.window, bg='#f0f0f0', padx=20, pady=10)
        stats_frame.pack(fill=tk.X)
        
        # Calcular estad√≠sticas clave
        dominant_emotion = max(emotion_avgs)
        dominant_name = emotion_names[emotion_avgs.index(dominant_emotion)]
        
        fear_avg = np.mean(emotions['fear'])
        sad_avg = np.mean(emotions['sad'])
        wellbeing_score = np.mean(emotions['happy']) - (fear_avg + sad_avg) / 2
        
        # Mostrar estad√≠sticas
        tk.Label(stats_frame, text=f"üé≠ Emoci√≥n Dominante: {dominant_name.upper()} ({dominant_emotion:.1f}%)",
                font=('Arial', 12, 'bold'), bg='#f0f0f0').pack(anchor='w')
        
        tk.Label(stats_frame, text=f"üòä √çndice de Bienestar: {wellbeing_score:.1f}% (felicidad - ansiedad/tristeza)",
                font=('Arial', 11), bg='#f0f0f0').pack(anchor='w')
        
        tk.Label(stats_frame, text=f"‚è±Ô∏è Duraci√≥n: {timestamps[-1] // 60} minutos {timestamps[-1] % 60} segundos",
                font=('Arial', 11), bg='#f0f0f0').pack(anchor='w')
        
        # Identificar momentos cr√≠ticos (ansiedad > 70%)
        critical_moments = [t for t, f in zip(timestamps, emotions['fear']) if f > 70]
        if critical_moments:
            tk.Label(stats_frame, 
                    text=f"‚ö†Ô∏è Momentos de Alta Ansiedad: {len(critical_moments)} detectados",
                    font=('Arial', 11), bg='#f0f0f0', fg='red').pack(anchor='w')
    
    def compare_sessions(self, session_id1, session_id2):
        """
        Compara dos sesiones lado a lado.
        
        ¬øPara qu√© sirve?
        - Ver si el paciente est√° mejorando entre sesiones
        - Identificar qu√© emociones han cambiado m√°s
        - Mostrar progreso visual al paciente
        """
        # Limpiar ventana
        for widget in self.window.winfo_children():
            widget.destroy()
        
        # Obtener datos de ambas sesiones
        data1 = self.db.get_session_emotions(session_id1)
        data2 = self.db.get_session_emotions(session_id2)
        
        # Calcular promedios
        emotions1 = self._calculate_averages(data1)
        emotions2 = self._calculate_averages(data2)
        
        # Crear gr√°fico comparativo
        fig, ax = plt.subplots(figsize=(10, 6))
        
        emotion_names = list(emotions1.keys())
        x = np.arange(len(emotion_names))
        width = 0.35
        
        bars1 = ax.bar(x - width/2, emotions1.values(), width, 
                      label='Sesi√≥n Anterior', alpha=0.8)
        bars2 = ax.bar(x + width/2, emotions2.values(), width, 
                      label='Sesi√≥n Actual', alpha=0.8)
        
        ax.set_ylabel('Intensidad Promedio (%)')
        ax.set_title('Comparaci√≥n Entre Sesiones', fontweight='bold')
        ax.set_xticks(x)
        ax.set_xticklabels(emotion_names)
        ax.legend()
        ax.grid(True, alpha=0.3, axis='y')
        
        plt.tight_layout()
        
        canvas = FigureCanvasTkAgg(fig, master=self.window)
        canvas.draw()
        canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True)
        
        # An√°lisis de cambios
        changes_frame = tk.Frame(self.window, bg='#f0f0f0', padx=20, pady=10)
        changes_frame.pack(fill=tk.X)
        
        tk.Label(changes_frame, text="üìä An√°lisis de Cambios:", 
                font=('Arial', 12, 'bold'), bg='#f0f0f0').pack(anchor='w')
        
        for emotion in emotion_names:
            change = emotions2[emotion] - emotions1[emotion]
            arrow = "üìà" if change > 0 else "üìâ" if change < 0 else "‚û°Ô∏è"
            color = "green" if (emotion == 'happy' and change > 0) or \
                              (emotion in ['fear', 'sad', 'angry'] and change < 0) else "red"
            
            tk.Label(changes_frame, 
                    text=f"{arrow} {emotion.capitalize()}: {change:+.1f}%",
                    font=('Arial', 11), bg='#f0f0f0', fg=color).pack(anchor='w')
    
    def _calculate_averages(self, emotion_data):
        """Calcula promedios de emociones desde datos de sesi√≥n"""
        if not emotion_data:
            return {e: 0 for e in ['happy', 'sad', 'angry', 'fear', 'surprise', 'disgust']}
        
        return {
            'happy': np.mean([row[1] for row in emotion_data]),
            'sad': np.mean([row[2] for row in emotion_data]),
            'angry': np.mean([row[3] for row in emotion_data]),
            'fear': np.mean([row[4] for row in emotion_data]),
            'surprise': np.mean([row[5] for row in emotion_data]),
            'disgust': np.mean([row[6] for row in emotion_data])
        }
    
    def show_patient_history(self, patient_id):
        """
        Muestra historial completo del paciente.
        
        ¬øQu√© muestra?
        - Lista de todas las sesiones
        - Gr√°fico de tendencia a largo plazo
        - Progreso general del tratamiento
        """
        sessions = self.db.get_patient_sessions(patient_id, limit=20)
        
        # Crear lista de sesiones
        frame = tk.Frame(self.window)
        frame.pack(fill=tk.BOTH, expand=True, padx=20, pady=20)
        
        tk.Label(frame, text=f"Historial del Paciente {patient_id}", 
                font=('Arial', 14, 'bold')).pack()
        
        # Tabla de sesiones
        tree = ttk.Treeview(frame, columns=('Fecha', 'Duraci√≥n', 'Tipo'), show='headings')
        tree.heading('Fecha', text='Fecha')
        tree.heading('Duraci√≥n', text='Duraci√≥n (min)')
        tree.heading('Tipo', text='Tipo de Sesi√≥n')
        
        for session in sessions:
            session_id, timestamp, duration, session_type, notes = session
            date = datetime.fromisoformat(timestamp).strftime('%Y-%m-%d %H:%M')
            tree.insert('', 'end', values=(date, duration // 60, session_type))
        
        tree.pack(fill=tk.BOTH, expand=True)
        
        # Bot√≥n para ver detalles
        def on_select(event):
            selected = tree.selection()
            if selected:
                item = tree.item(selected[0])
                # Aqu√≠ se abrir√≠a el detalle de la sesi√≥n
                pass
        
        tree.bind('<<TreeviewSelect>>', on_select)
    
    def run(self):
        """Inicia la interfaz gr√°fica"""
        self.window.mainloop()
```

#### üìù ¬øC√≥mo se usa?

```python
# Ejemplo de uso para el terapeuta
from therapy_tools.session_database import SessionDatabase
from therapy_tools.therapist_dashboard import TherapistDashboard

# Conectar a la base de datos
db = SessionDatabase()

# Crear dashboard
dashboard = TherapistDashboard(db)

# Ver resumen de la √∫ltima sesi√≥n
dashboard.show_session_summary(session_id=15)

# O comparar dos sesiones
dashboard.compare_sessions(session_id1=10, session_id2=15)

# O ver historial completo del paciente
dashboard.show_patient_history(patient_id='PAC_001')

# Iniciar interfaz
dashboard.run()
```

### 3. **Sistema de Privacidad y √âtica (Protecci√≥n de Datos)**

#### üéØ ¬øQu√© se hace?
Se implementa un sistema completo de protecci√≥n de datos personales y consentimiento informado, cumpliendo con regulaciones de privacidad.

#### ü§î ¬øPor qu√© es CR√çTICO?
**Problema actual**: El sistema no tiene ninguna protecci√≥n de privacidad. Esto es ILEGAL en contexto terap√©utico.

**Riesgos sin este sistema**:
- ‚ùå **Violaci√≥n de GDPR/HIPAA**: Multas de hasta ‚Ç¨20 millones o 4% de ingresos anuales
- ‚ùå **P√©rdida de licencia profesional**: Terapeutas pueden perder su licencia
- ‚ùå **Demandas legales**: Pacientes pueden demandar por violaci√≥n de privacidad
- ‚ùå **P√©rdida de confianza**: Pacientes no querr√°n usar el sistema
- ‚ùå **Datos sensibles expuestos**: Informaci√≥n de salud mental es extremadamente sensible

**Beneficios de agregarlo**:
- ‚úÖ **Cumplimiento legal**: GDPR, HIPAA, leyes locales de protecci√≥n de datos
- ‚úÖ **Consentimiento informado**: Paciente sabe exactamente qu√© se graba y por qu√©
- ‚úÖ **Anonimizaci√≥n**: Protege identidad del paciente
- ‚úÖ **Encriptaci√≥n**: Datos seguros incluso si hay robo de dispositivo
- ‚úÖ **Derecho al olvido**: Paciente puede solicitar eliminaci√≥n de sus datos
- ‚úÖ **Auditor√≠a**: Registro de qui√©n accede a qu√© datos y cu√°ndo

#### üîß ¬øC√≥mo se implementa?

**Crear**: `therapy_tools/privacy_manager.py`
```python
import hashlib
import json
from cryptography.fernet import Fernet
from datetime import datetime
import tkinter as tk
from tkinter import messagebox, scrolledtext

class PrivacyManager:
    """
    Gestiona privacidad, consentimiento y protecci√≥n de datos.
    Cumple con GDPR, HIPAA y mejores pr√°cticas de seguridad.
    """
    def __init__(self, encryption_key=None):
        self.consent_given = False
        self.anonymize = True
        
        # Generar o cargar clave de encriptaci√≥n
        if encryption_key:
            self.cipher = Fernet(encryption_key)
        else:
            self.cipher = Fernet(Fernet.generate_key())
        
        # Registro de accesos (auditor√≠a)
        self.access_log = []
    
    def request_consent(self, patient_name=None):
        """
        Muestra formulario de consentimiento informado.
        
        ¬øPor qu√© es necesario?
        - Legalmente requerido antes de grabar/procesar datos
        - Paciente debe entender qu√© se hace con sus datos
        - Debe ser voluntario y revocable
        
        Retorna: True si acepta, False si rechaza
        """
        consent_window = tk.Tk()
        consent_window.title("Consentimiento Informado - Sistema de Reconocimiento Emocional")
        consent_window.geometry("700x600")
        
        # Texto del consentimiento
        consent_text = """
CONSENTIMIENTO INFORMADO PARA USO DE SISTEMA DE RECONOCIMIENTO EMOCIONAL

Estimado/a paciente,

Le solicitamos su consentimiento para utilizar un sistema de reconocimiento de emociones 
faciales durante sus sesiones terap√©uticas.

¬øQU√â HACE ESTE SISTEMA?
- Analiza su rostro mediante c√°mara web en tiempo real
- Detecta expresiones faciales asociadas a 6 emociones b√°sicas
- Registra datos emocionales durante la sesi√≥n (NO graba video)
- Genera gr√°ficos y estad√≠sticas para an√°lisis terap√©utico

¬øQU√â DATOS SE RECOPILAN?
- Puntuaciones de emociones (n√∫meros del 0-100) cada segundo
- Fecha y duraci√≥n de sesiones
- Notas del terapeuta (si las hay)
- NO se graban im√°genes ni videos de su rostro
- NO se almacena informaci√≥n identificable (nombre, direcci√≥n, etc.)

¬øC√ìMO SE PROTEGEN SUS DATOS?
- Identificaci√≥n an√≥nima (c√≥digo ID, no su nombre)
- Encriptaci√≥n de datos en reposo
- Acceso restringido solo a su terapeuta
- Almacenamiento local seguro (no en la nube)
- Cumplimiento con GDPR y regulaciones de privacidad

SUS DERECHOS:
‚úì Puede rechazar el uso del sistema sin afectar su tratamiento
‚úì Puede revocar este consentimiento en cualquier momento
‚úì Puede solicitar acceso a sus datos
‚úì Puede solicitar correcci√≥n de datos incorrectos
‚úì Puede solicitar eliminaci√≥n completa de sus datos
‚úì Puede solicitar copia de sus datos en formato portable

LIMITACIONES DEL SISTEMA:
‚ö† Este sistema NO es un diagn√≥stico m√©dico
‚ö† Es una herramienta complementaria, no reemplazo del juicio cl√≠nico
‚ö† Puede tener imprecisiones en la detecci√≥n de emociones
‚ö† Requiere buena iluminaci√≥n para funcionar correctamente

DURACI√ìN DEL ALMACENAMIENTO:
- Sus datos se conservar√°n durante el tratamiento activo
- Despu√©s del alta, se conservar√°n seg√∫n regulaciones locales (t√≠picamente 5-10 a√±os)
- Puede solicitar eliminaci√≥n anticipada en cualquier momento

CONTACTO:
Si tiene preguntas sobre este sistema o sus datos, contacte a:
[Nombre del terapeuta]
[Informaci√≥n de contacto]
[Informaci√≥n del responsable de protecci√≥n de datos]

---

Al hacer clic en "ACEPTO", confirmo que:
1. He le√≠do y comprendido esta informaci√≥n
2. He tenido oportunidad de hacer preguntas
3. Consiento voluntariamente el uso de este sistema
4. Entiendo que puedo revocar este consentimiento en cualquier momento
        """
        
        # √Årea de texto con scroll
        text_area = scrolledtext.ScrolledText(consent_window, wrap=tk.WORD, 
                                              width=80, height=25, font=('Arial', 10))
        text_area.insert(tk.INSERT, consent_text)
        text_area.config(state=tk.DISABLED)  # Solo lectura
        text_area.pack(padx=10, pady=10)
        
        # Variable para almacenar respuesta
        consent_result = {'accepted': False}
        
        def accept_consent():
            # Registrar consentimiento
            self.consent_given = True
            self.log_access('CONSENT_GIVEN', patient_name or 'ANONYMOUS', 
                          'Patient accepted informed consent')
            consent_result['accepted'] = True
            consent_window.destroy()
        
        def reject_consent():
            self.consent_given = False
            self.log_access('CONSENT_REJECTED', patient_name or 'ANONYMOUS', 
                          'Patient rejected informed consent')
            consent_result['accepted'] = False
            consent_window.destroy()
        
        # Botones
        button_frame = tk.Frame(consent_window)
        button_frame.pack(pady=10)
        
        tk.Button(button_frame, text="‚úì ACEPTO", command=accept_consent, 
                 bg='green', fg='white', font=('Arial', 12, 'bold'),
                 width=15, height=2).pack(side=tk.LEFT, padx=10)
        
        tk.Button(button_frame, text="‚úó NO ACEPTO", command=reject_consent, 
                 bg='red', fg='white', font=('Arial', 12, 'bold'),
                 width=15, height=2).pack(side=tk.LEFT, padx=10)
        
        consent_window.mainloop()
        
        return consent_result['accepted']
    
    def anonymize_patient_id(self, patient_name, birth_date):
        """
        Genera ID an√≥nimo del paciente usando hash.
        
        ¬øPor qu√©?
        - No almacenar nombres reales en la base de datos
        - Proteger identidad en caso de filtraci√≥n de datos
        - Cumplir con principio de minimizaci√≥n de datos
        
        Ejemplo:
        - Input: "Juan P√©rez", "1990-05-15"
        - Output: "PAC_a3f5b2c8d1e4f6a7"
        """
        # Combinar nombre y fecha de nacimiento
        combined = f"{patient_name}_{birth_date}".encode('utf-8')
        
        # Generar hash SHA-256
        hash_object = hashlib.sha256(combined)
        hash_hex = hash_object.hexdigest()[:16]  # Primeros 16 caracteres
        
        return f"PAC_{hash_hex}"
    
    def encrypt_sensitive_data(self, data):
        """
        Encripta datos sensibles antes de almacenar.
        
        ¬øQu√© se encripta?
        - Notas del terapeuta (pueden contener informaci√≥n sensible)
        - Cualquier comentario o anotaci√≥n
        - Metadatos que puedan identificar al paciente
        
        ¬øPor qu√©?
        - Protecci√≥n en caso de robo de dispositivo
        - Cumplimiento con est√°ndares de seguridad
        - Defensa en profundidad (m√∫ltiples capas de seguridad)
        """
        if isinstance(data, str):
            data = data.encode('utf-8')
        
        encrypted = self.cipher.encrypt(data)
        return encrypted.decode('utf-8')
    
    def decrypt_sensitive_data(self, encrypted_data):
        """Desencripta datos para visualizaci√≥n autorizada"""
        if isinstance(encrypted_data, str):
            encrypted_data = encrypted_data.encode('utf-8')
        
        decrypted = self.cipher.decrypt(encrypted_data)
        return decrypted.decode('utf-8')
    
    def log_access(self, action, user, details=''):
        """
        Registra todos los accesos a datos de pacientes.
        
        ¬øPor qu√© es importante?
        - Auditor√≠a: saber qui√©n accedi√≥ a qu√© y cu√°ndo
        - Detecci√≥n de accesos no autorizados
        - Cumplimiento regulatorio (GDPR requiere logs)
        - Investigaci√≥n en caso de incidente de seguridad
        """
        log_entry = {
            'timestamp': datetime.now().isoformat(),
            'action': action,  # Ej: 'VIEW_SESSION', 'EXPORT_DATA', 'DELETE_DATA'
            'user': user,
            'details': details
        }
        self.access_log.append(log_entry)
        
        # Guardar en archivo de log
        with open('access_log.json', 'a') as f:
            f.write(json.dumps(log_entry) + '\n')
    
    def export_patient_data(self, patient_id, database):
        """
        Exporta todos los datos del paciente (Derecho de acceso GDPR).
        
        ¬øPor qu√©?
        - GDPR Art. 15: Derecho de acceso del interesado
        - Paciente puede solicitar copia de todos sus datos
        - Debe ser en formato legible y portable
        """
        self.log_access('EXPORT_DATA', patient_id, 'Patient requested data export')
        
        # Obtener todas las sesiones
        sessions = database.get_patient_sessions(patient_id, limit=1000)
        
        export_data = {
            'patient_id': patient_id,
            'export_date': datetime.now().isoformat(),
            'sessions': []
        }
        
        for session in sessions:
            session_id, timestamp, duration, session_type, notes = session
            emotions = database.get_session_emotions(session_id)
            
            export_data['sessions'].append({
                'date': timestamp,
                'duration_minutes': duration // 60,
                'type': session_type,
                'emotions_timeline': emotions
            })
        
        # Guardar en JSON
        filename = f"patient_data_export_{patient_id}_{datetime.now().strftime('%Y%m%d')}.json"
        with open(filename, 'w') as f:
            json.dump(export_data, f, indent=2)
        
        return filename
    
    def delete_patient_data(self, patient_id, database):
        """
        Elimina todos los datos del paciente (Derecho al olvido GDPR).
        
        ¬øCu√°ndo se usa?
        - Paciente revoca consentimiento
        - Paciente solicita eliminaci√≥n de datos
        - Fin del per√≠odo de retenci√≥n legal
        
        ‚ö†Ô∏è IRREVERSIBLE - Requiere confirmaci√≥n m√∫ltiple
        """
        # Confirmaci√≥n de seguridad
        confirm = messagebox.askyesno(
            "‚ö†Ô∏è ELIMINAR DATOS - ACCI√ìN IRREVERSIBLE",
            f"¬øEst√° SEGURO de eliminar TODOS los datos del paciente {patient_id}?\n\n"
            "Esta acci√≥n NO se puede deshacer.\n"
            "Se eliminar√°n:\n"
            "- Todas las sesiones\n"
            "- Todos los datos emocionales\n"
            "- Todas las notas\n\n"
            "¬øContinuar?"
        )
        
        if not confirm:
            return False
        
        # Segunda confirmaci√≥n
        confirm2 = messagebox.askyesno(
            "‚ö†Ô∏è CONFIRMACI√ìN FINAL",
            "Esta es su √∫ltima oportunidad.\n\n"
            "¬øEliminar PERMANENTEMENTE todos los datos?"
        )
        
        if not confirm2:
            return False
        
        # Registrar eliminaci√≥n ANTES de borrar
        self.log_access('DELETE_ALL_DATA', patient_id, 
                       'All patient data permanently deleted')
        
        # Eliminar de base de datos
        database.conn.execute('DELETE FROM emotion_snapshots WHERE session_id IN '
                            '(SELECT id FROM sessions WHERE patient_id = ?)', 
                            (patient_id,))
        database.conn.execute('DELETE FROM sessions WHERE patient_id = ?', 
                            (patient_id,))
        database.conn.commit()
        
        messagebox.showinfo("‚úì Datos Eliminados", 
                          f"Todos los datos del paciente {patient_id} han sido eliminados.")
        
        return True
    
    def check_data_retention_policy(self, database, retention_years=7):
        """
        Verifica y elimina datos antiguos seg√∫n pol√≠tica de retenci√≥n.
        
        ¬øPor qu√©?
        - GDPR: No conservar datos m√°s tiempo del necesario
        - Minimizaci√≥n de riesgo: Menos datos = menos riesgo
        - Regulaciones profesionales: T√≠picamente 5-10 a√±os
        
        Se ejecuta autom√°ticamente cada mes.
        """
        from datetime import timedelta
        
        cutoff_date = datetime.now() - timedelta(days=retention_years * 365)
        
        # Buscar sesiones antiguas
        cursor = database.conn.execute('''
            SELECT DISTINCT patient_id, COUNT(*) as session_count
            FROM sessions
            WHERE timestamp < ?
            GROUP BY patient_id
        ''', (cutoff_date.isoformat(),))
        
        old_data = cursor.fetchall()
        
        if old_data:
            message = "Se encontraron datos antiguos que exceden la pol√≠tica de retenci√≥n:\n\n"
            for patient_id, count in old_data:
                message += f"- Paciente {patient_id}: {count} sesiones antiguas\n"
            
            message += f"\n¬øEliminar datos anteriores a {cutoff_date.strftime('%Y-%m-%d')}?"
            
            if messagebox.askyesno("Pol√≠tica de Retenci√≥n de Datos", message):
                for patient_id, _ in old_data:
                    database.conn.execute('''
                        DELETE FROM emotion_snapshots WHERE session_id IN
                        (SELECT id FROM sessions WHERE patient_id = ? AND timestamp < ?)
                    ''', (patient_id, cutoff_date.isoformat()))
                    
                    database.conn.execute('''
                        DELETE FROM sessions WHERE patient_id = ? AND timestamp < ?
                    ''', (patient_id, cutoff_date.isoformat()))
                
                database.conn.commit()
                self.log_access('RETENTION_POLICY', 'SYSTEM', 
                              f'Deleted data older than {retention_years} years')
```

#### üìù ¬øC√≥mo se integra?

**Modificar**: `examples/video_stream.py`
```python
from therapy_tools.privacy_manager import PrivacyManager

class SecureTherapyVideoStream(TherapyVideoStream):
    def __init__(self, cam, emotion_recognition_system, patient_name, birth_date):
        # Inicializar gestor de privacidad
        self.privacy = PrivacyManager()
        
        # PASO 1: Solicitar consentimiento ANTES de hacer nada
        if not self.privacy.request_consent(patient_name):
            print("‚ùå Consentimiento rechazado. No se puede iniciar sesi√≥n.")
            return
        
        # PASO 2: Anonimizar ID del paciente
        patient_id = self.privacy.anonymize_patient_id(patient_name, birth_date)
        
        # PASO 3: Inicializar sesi√≥n con ID an√≥nimo
        super().__init__(cam, emotion_recognition_system, patient_id)
        
        # Registrar inicio de sesi√≥n
        self.privacy.log_access('START_SESSION', patient_id, 'New therapy session started')
```

### 4. **Modo de Calibraci√≥n Personal (Personalizaci√≥n del Sistema)**

#### üéØ ¬øQu√© se hace?
Se crea un proceso de calibraci√≥n que ajusta el sistema a la forma √∫nica en que cada persona expresa emociones.

#### ü§î ¬øPor qu√© es necesario?
**Problema actual**: El sistema usa umbrales gen√©ricos que asumen que todos expresamos emociones igual. Esto es FALSO.

**Realidad de las expresiones faciales**:
- üë§ **Variabilidad individual**: Algunas personas son muy expresivas, otras m√°s contenidas
- üåç **Diferencias culturales**: Culturas asi√°ticas tienden a expresiones m√°s sutiles
- üß† **Neurodivergencia**: Personas con autismo pueden tener expresiones at√≠picas
- üòê **"Resting face"**: Algunas personas tienen cara de enojado/triste en estado neutral
- üé≠ **Rango expresivo**: Unos tienen sonrisas enormes, otros apenas mueven los labios

**Ejemplo del problema**:
```
Paciente A (muy expresivo):
- Su "neutral" = 20% felicidad detectada
- Su "feliz" = 95% felicidad detectada
- Rango √∫til: 20-95%

Paciente B (poco expresivo):
- Su "neutral" = 5% felicidad detectada
- Su "feliz" = 45% felicidad detectada
- Rango √∫til: 5-45%

Sin calibraci√≥n: El sistema pensar√≠a que B nunca est√° feliz (solo 45%)
Con calibraci√≥n: El sistema entiende que 45% es MUY feliz para B
```

**Beneficios de agregarlo**:
- ‚úÖ **Precisi√≥n personalizada**: Sistema ajustado a cada individuo
- ‚úÖ **Menos falsos positivos**: No confundir "neutral" con "triste"
- ‚úÖ **Mejor seguimiento**: Detectar cambios sutiles en el mismo paciente
- ‚úÖ **Inclusi√≥n**: Funciona bien para personas neurodivergentes
- ‚úÖ **Confianza del paciente**: Ve que el sistema "lo entiende"

#### üîß ¬øC√≥mo se implementa?

**Crear**: `therapy_tools/personal_calibration.py`
```python
import numpy as np
import json
import time
import cv2

class PersonalCalibration:
    """
    Calibra el sistema para cada paciente individual.
    
    Proceso de calibraci√≥n (5-10 minutos):
    1. Capturar estado neutral (30 segundos)
    2. Capturar cada emoci√≥n b√°sica (10 segundos cada una)
    3. Calcular rangos personalizados
    4. Ajustar umbrales del sistema
    """
    def __init__(self, emotion_recognition_system):
        self.emotion_system = emotion_recognition_system
        
        # Almacena l√≠neas base personalizadas
        self.baseline_emotions = {
            'neutral': {},
            'happy': {},
            'sad': {},
            'angry': {},
            'fear': {},
            'surprise': {},
            'disgust': {}
        }
        
        # Rangos personalizados (min-max para cada emoci√≥n)
        self.personal_ranges = {}
        
        # Factores de ajuste
        self.adjustment_factors = {}
    
    def start_calibration_wizard(self, camera, patient_id):
        """
        Asistente interactivo de calibraci√≥n.
        
        ¬øC√≥mo funciona?
        - Muestra instrucciones en pantalla
        - Gu√≠a al paciente paso a paso
        - Captura datos mientras el paciente expresa cada emoci√≥n
        - Calcula autom√°ticamente los ajustes necesarios
        """
        print("=" * 60)
        print("üéØ CALIBRACI√ìN PERSONAL DEL SISTEMA")
        print("=" * 60)
        print("\nEste proceso tomar√° aproximadamente 5-7 minutos.")
        print("Por favor, siga las instrucciones en pantalla.\n")
        input("Presione ENTER cuando est√© listo para comenzar...")
        
        # PASO 1: Calibrar estado neutral
        print("\nüìç PASO 1/7: Estado Neutral")
        print("Por favor, mantenga una expresi√≥n facial relajada y neutral.")
        print("No sonr√≠a, no frunza el ce√±o, solo rel√°jese.")
        self.calibrate_neutral(camera, duration=30)
        
        # PASO 2-7: Calibrar cada emoci√≥n
        emotions_to_calibrate = [
            ('happy', 'üòä Felicidad', 'Sonr√≠a ampliamente, como si algo muy bueno hubiera pasado'),
            ('sad', 'üò¢ Tristeza', 'Ponga cara triste, como si recibiera malas noticias'),
            ('angry', 'üò† Enojo', 'Frunza el ce√±o y apriete la mand√≠bula, como si estuviera molesto'),
            ('fear', 'üò® Miedo', 'Abra los ojos ampliamente, como si se asustara'),
            ('surprise', 'üò≤ Sorpresa', 'Abra la boca y los ojos, como si algo inesperado pasara'),
            ('disgust', 'ü§¢ Disgusto', 'Arrugue la nariz, como si oliera algo desagradable')
        ]
        
        for i, (emotion_key, emotion_name, instruction) in enumerate(emotions_to_calibrate, 2):
            print(f"\nüìç PASO {i}/7: {emotion_name}")
            print(f"Instrucci√≥n: {instruction}")
            input("Presione ENTER cuando est√© listo...")
            self.calibrate_emotion(camera, emotion_key, duration=10)
        
        # PASO FINAL: Calcular ajustes
        print("\nüîß Calculando ajustes personalizados...")
        self.calculate_adjustment_factors()
        
        # Guardar calibraci√≥n
        self.save_calibration(patient_id)
        
        print("\n‚úÖ ¬°Calibraci√≥n completada!")
        print(f"El sistema ahora est√° personalizado para el paciente {patient_id}")
        print("\nResumen de calibraci√≥n:")
        self.print_calibration_summary()
    
    def calibrate_neutral(self, camera, duration=30):
        """
        Captura el estado neutral del paciente.
        
        ¬øPor qu√© es importante?
        - Establece la l√≠nea base de comparaci√≥n
        - Identifica la "cara de descanso" del paciente
        - Permite detectar desviaciones de lo normal
        """
        print(f"‚è±Ô∏è Capturando durante {duration} segundos...")
        
        samples = []
        start_time = time.time()
        countdown_shown = set()
        
        while time.time() - start_time < duration:
            ret, frame = camera.read()
            if not ret:
                continue
            
            # Procesar frame
            try:
                # Obtener emociones del frame actual
                emotions = self._get_emotions_from_frame(frame)
                if emotions:
                    samples.append(emotions)
            except:
                pass
            
            # Mostrar countdown
            remaining = int(duration - (time.time() - start_time))
            if remaining not in countdown_shown and remaining <= 10:
                print(f"‚è±Ô∏è {remaining} segundos restantes...")
                countdown_shown.add(remaining)
            
            # Mostrar video con overlay
            cv2.putText(frame, "ESTADO NEUTRAL - Mantenga expresion relajada", 
                       (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
            cv2.putText(frame, f"Tiempo restante: {remaining}s", 
                       (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
            cv2.imshow('Calibracion', frame)
            cv2.waitKey(1)
        
        cv2.destroyAllWindows()
        
        # Calcular promedios
        if samples:
            self.baseline_emotions['neutral'] = {
                emotion: np.mean([s[emotion] for s in samples])
                for emotion in samples[0].keys()
            }
            print(f"‚úì Capturados {len(samples)} muestras de estado neutral")
        else:
            print("‚ö†Ô∏è No se pudieron capturar muestras. Intente de nuevo.")
    
    def calibrate_emotion(self, camera, emotion_key, duration=10):
        """
        Captura una emoci√≥n espec√≠fica expresada por el paciente.
        
        ¬øQu√© se mide?
        - Intensidad m√°xima que el paciente puede expresar
        - Caracter√≠sticas faciales espec√≠ficas de su expresi√≥n
        - Variabilidad en su expresi√≥n de esa emoci√≥n
        """
        print(f"‚è±Ô∏è Exprese {emotion_key} durante {duration} segundos...")
        
        samples = []
        start_time = time.time()
        countdown_shown = set()
        
        while time.time() - start_time < duration:
            ret, frame = camera.read()
            if not ret:
                continue
            
            try:
                emotions = self._get_emotions_from_frame(frame)
                if emotions:
                    samples.append(emotions)
            except:
                pass
            
            remaining = int(duration - (time.time() - start_time))
            if remaining not in countdown_shown and remaining <= 5:
                print(f"‚è±Ô∏è {remaining} segundos...")
                countdown_shown.add(remaining)
            
            # Mostrar video con overlay
            cv2.putText(frame, f"EXPRESE: {emotion_key.upper()}", 
                       (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)
            cv2.putText(frame, f"Tiempo restante: {remaining}s", 
                       (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)
            cv2.imshow('Calibracion', frame)
            cv2.waitKey(1)
        
        cv2.destroyAllWindows()
        
        if samples:
            self.baseline_emotions[emotion_key] = {
                emotion: np.mean([s[emotion] for s in samples])
                for emotion in samples[0].keys()
            }
            print(f"‚úì Capturados {len(samples)} muestras de {emotion_key}")
        else:
            print(f"‚ö†Ô∏è No se pudieron capturar muestras de {emotion_key}")
    
    def calculate_adjustment_factors(self):
        """
        Calcula factores de ajuste basados en calibraci√≥n.
        
        ¬øC√≥mo funciona?
        1. Compara neutral vs. cada emoci√≥n
        2. Calcula el rango personal (diferencia entre neutral y m√°ximo)
        3. Crea factores de escala para normalizar
        
        Ejemplo:
        - Paciente A: neutral=20%, feliz=95% ‚Üí rango=75%
        - Paciente B: neutral=5%, feliz=45% ‚Üí rango=40%
        - Factor de ajuste para B: 75/40 = 1.875
        - Ahora 45% de B se escala a 84%, comparable con A
        """
        neutral = self.baseline_emotions['neutral']
        
        for emotion in ['happy', 'sad', 'angry', 'fear', 'surprise', 'disgust']:
            if emotion in self.baseline_emotions and self.baseline_emotions[emotion]:
                # Calcular rango personal
                neutral_value = neutral.get(emotion, 0)
                max_value = self.baseline_emotions[emotion].get(emotion, 0)
                personal_range = max_value - neutral_value
                
                # Rango "est√°ndar" esperado (basado en poblaci√≥n general)
                standard_range = 70  # Asumimos que el rango t√≠pico es 70%
                
                # Factor de ajuste
                if personal_range > 0:
                    adjustment_factor = standard_range / personal_range
                else:
                    adjustment_factor = 1.0
                
                self.adjustment_factors[emotion] = {
                    'neutral_baseline': neutral_value,
                    'max_observed': max_value,
                    'personal_range': personal_range,
                    'scale_factor': adjustment_factor
                }
                
                self.personal_ranges[emotion] = {
                    'min': neutral_value,
                    'max': max_value
                }
    
    def adjust_emotion_score(self, emotion, raw_score):
        """
        Ajusta una puntuaci√≥n de emoci√≥n usando calibraci√≥n personal.
        
        Esta funci√≥n se llama en tiempo real durante las sesiones.
        
        ¬øQu√© hace?
        1. Resta la l√≠nea base neutral
        2. Escala seg√∫n el rango personal
        3. Limita entre 0-100
        """
        if emotion not in self.adjustment_factors:
            return raw_score  # Sin calibraci√≥n, retornar valor original
        
        factors = self.adjustment_factors[emotion]
        
        # Restar l√≠nea base neutral
        adjusted = raw_score - factors['neutral_baseline']
        
        # Escalar seg√∫n rango personal
        adjusted = adjusted * factors['scale_factor']
        
        # Limitar entre 0-100
        adjusted = max(0, min(100, adjusted))
        
        return adjusted
    
    def save_calibration(self, patient_id):
        """Guarda calibraci√≥n para uso futuro"""
        calibration_data = {
            'patient_id': patient_id,
            'calibration_date': time.strftime('%Y-%m-%d %H:%M:%S'),
            'baseline_emotions': self.baseline_emotions,
            'adjustment_factors': self.adjustment_factors,
            'personal_ranges': self.personal_ranges
        }
        
        filename = f"calibration_{patient_id}.json"
        with open(filename, 'w') as f:
            json.dump(calibration_data, f, indent=2)
        
        print(f"üíæ Calibraci√≥n guardada en: {filename}")
    
    def load_calibration(self, patient_id):
        """Carga calibraci√≥n guardada previamente"""
        filename = f"calibration_{patient_id}.json"
        try:
            with open(filename, 'r') as f:
                calibration_data = json.load(f)
            
            self.baseline_emotions = calibration_data['baseline_emotions']
            self.adjustment_factors = calibration_data['adjustment_factors']
            self.personal_ranges = calibration_data['personal_ranges']
            
            print(f"‚úì Calibraci√≥n cargada para paciente {patient_id}")
            return True
        except FileNotFoundError:
            print(f"‚ö†Ô∏è No se encontr√≥ calibraci√≥n para {patient_id}")
            return False
    
    def print_calibration_summary(self):
        """Muestra resumen de la calibraci√≥n"""
        print("\n" + "=" * 60)
        print("RESUMEN DE CALIBRACI√ìN PERSONAL")
        print("=" * 60)
        
        for emotion, factors in self.adjustment_factors.items():
            print(f"\n{emotion.upper()}:")
            print(f"  L√≠nea base neutral: {factors['neutral_baseline']:.1f}%")
            print(f"  M√°ximo observado: {factors['max_observed']:.1f}%")
            print(f"  Rango personal: {factors['personal_range']:.1f}%")
            print(f"  Factor de escala: {factors['scale_factor']:.2f}x")
    
    def _get_emotions_from_frame(self, frame):
        """Helper: Obtiene emociones de un frame"""
        # Aqu√≠ se integra con el sistema de reconocimiento existente
        # Retorna diccionario de emociones
        pass

# Clase para integrar calibraci√≥n con el sistema existente
class CalibratedEmotionRecognitionSystem(EmotionRecognitionSystem):
    """
    Versi√≥n del sistema que usa calibraci√≥n personal.
    """
    def __init__(self, patient_id=None):
        super().__init__()
        self.calibration = PersonalCalibration(self)
        
        # Intentar cargar calibraci√≥n existente
        if patient_id:
            self.calibration.load_calibration(patient_id)
    
    def frame_processing(self, face_image):
        """Procesa frame aplicando calibraci√≥n personal"""
        # Procesamiento normal
        result = super().frame_processing(face_image)
        
        # Aplicar ajustes de calibraci√≥n si existen
        if self.calibration.adjustment_factors:
            # Ajustar cada emoci√≥n
            adjusted_emotions = {}
            for emotion, score in self.last_emotions.items():
                adjusted_emotions[emotion] = self.calibration.adjust_emotion_score(
                    emotion, score
                )
            
            # Actualizar visualizaci√≥n con emociones ajustadas
            result = self.emotions_visualization.main(adjusted_emotions, result)
        
        return result
```

#### üìù ¬øC√≥mo se usa?

```python
# PRIMERA SESI√ìN: Calibrar el sistema
from therapy_tools.personal_calibration import PersonalCalibration
from examples.camera import Camera

camera = Camera(0, 1280, 720)
emotion_system = EmotionRecognitionSystem()
calibration = PersonalCalibration(emotion_system)

# Ejecutar asistente de calibraci√≥n (5-7 minutos)
calibration.start_calibration_wizard(camera, patient_id='PAC_12345')

# SESIONES POSTERIORES: Usar calibraci√≥n guardada
from therapy_tools.personal_calibration import CalibratedEmotionRecognitionSystem

# El sistema carga autom√°ticamente la calibraci√≥n
calibrated_system = CalibratedEmotionRecognitionSystem(patient_id='PAC_12345')

# Usar normalmente - las emociones ya est√°n ajustadas
video_stream = VideoStream(camera, calibrated_system)
video_stream.run()
```

### 5. **Integraci√≥n con Ejercicios Terap√©uticos (Biofeedback Activo)**

#### üéØ ¬øQu√© se hace?
Se crean ejercicios terap√©uticos interactivos que usan el reconocimiento emocional en tiempo real para dar feedback inmediato al paciente.

#### ü§î ¬øPor qu√© es necesario?
**Problema actual**: El sistema solo OBSERVA emociones, no ayuda activamente a regularlas.

**Concepto de Biofeedback**:
- El paciente ve sus emociones en tiempo real
- Practica t√©cnicas de regulaci√≥n
- Recibe confirmaci√≥n inmediata cuando funciona
- Aprende qu√© t√©cnicas son m√°s efectivas para √©l/ella

**Beneficios terap√©uticos**:
- ‚úÖ **Aprendizaje acelerado**: Ver resultados inmediatos motiva y ense√±a
- ‚úÖ **Autoeficacia**: "Puedo controlar mi ansiedad" (evidencia visual)
- ‚úÖ **Personalizaci√≥n**: Descubrir qu√© t√©cnicas funcionan mejor
- ‚úÖ **Pr√°ctica guiada**: No solo teor√≠a, sino pr√°ctica con feedback
- ‚úÖ **Medici√≥n objetiva**: Saber si el ejercicio realmente funcion√≥
- ‚úÖ **Motivaci√≥n**: Gamificaci√≥n y logros visuales

**Aplicaciones cl√≠nicas**:
- üò∞ **Trastornos de ansiedad**: Ejercicios de respiraci√≥n con monitoreo de miedo
- üò¢ **Depresi√≥n**: Activaci√≥n conductual con seguimiento de estado de √°nimo
- üò° **Manejo de ira**: T√©cnicas de enfriamiento con feedback visual
- üßò **Mindfulness**: Meditaci√≥n guiada con medici√≥n de calma
- üò® **TEPT**: Exposici√≥n gradual con monitoreo de ansiedad

#### üîß ¬øC√≥mo se implementa?

**Crear**: `therapy_tools/therapeutic_exercises.py`
```python
import time
import cv2
import numpy as np
from datetime import datetime
import matplotlib.pyplot as plt

class TherapeuticExercises:
    """
    Biblioteca de ejercicios terap√©uticos con biofeedback emocional.
    """
    def __init__(self, emotion_recognition_system, camera):
        self.emotion_system = emotion_recognition_system
        self.camera = camera
        
        # Cat√°logo de ejercicios disponibles
        self.exercises = {
            'breathing_478': BreathingExercise478(self),
            'progressive_relaxation': ProgressiveRelaxation(self),
            'grounding_54321': GroundingExercise54321(self),
            'mindfulness_body_scan': MindfulnessBodyScan(self),
            'exposure_gradual': GradualExposureExercise(self)
        }
    
    def list_exercises(self):
        """Muestra ejercicios disponibles"""
        print("\n" + "=" * 60)
        print("EJERCICIOS TERAP√âUTICOS DISPONIBLES")
        print("=" * 60)
        
        for key, exercise in self.exercises.items():
            print(f"\n{exercise.name}")
            print(f"  Duraci√≥n: {exercise.duration} minutos")
            print(f"  Indicado para: {exercise.indications}")
            print(f"  Objetivo: {exercise.goal}")
    
    def start_exercise(self, exercise_key):
        """Inicia un ejercicio espec√≠fico"""
        if exercise_key not in self.exercises:
            print(f"‚ùå Ejercicio '{exercise_key}' no encontrado")
            return None
        
        exercise = self.exercises[exercise_key]
        print(f"\nüéØ Iniciando: {exercise.name}")
        print(f"Duraci√≥n estimada: {exercise.duration} minutos\n")
        
        results = exercise.run()
        return results


class BreathingExercise478:
    """
    Ejercicio de Respiraci√≥n 4-7-8 (Dr. Andrew Weil)
    
    ¬øQu√© es?
    - Inhalar por 4 segundos
    - Retener por 7 segundos
    - Exhalar por 8 segundos
    - Repetir 4-8 ciclos
    
    ¬øPara qu√© sirve?
    - Reducir ansiedad r√°pidamente
    - Activar sistema nervioso parasimp√°tico
    - Preparar para dormir
    - Manejo de ataques de p√°nico
    
    ¬øC√≥mo usa el biofeedback?
    - Monitorea nivel de miedo/ansiedad en tiempo real
    - Muestra gr√°fico de reducci√≥n de ansiedad
    - Confirma cuando la t√©cnica est√° funcionando
    """
    def __init__(self, parent):
        self.parent = parent
        self.name = "Respiraci√≥n 4-7-8"
        self.duration = 5
        self.indications = "Ansiedad, estr√©s, insomnio, ataques de p√°nico"
        self.goal = "Reducir ansiedad en 30-50%"
        
        # Datos de la sesi√≥n
        self.emotion_timeline = []
        self.timestamps = []
    
    def run(self):
        """Ejecuta el ejercicio con gu√≠a visual y monitoreo"""
        print("=" * 60)
        print("EJERCICIO: RESPIRACI√ìN 4-7-8")
        print("=" * 60)
        print("\nInstrucciones:")
        print("1. Si√©ntese c√≥modamente con la espalda recta")
        print("2. Coloque la punta de la lengua detr√°s de los dientes superiores")
        print("3. Siga las instrucciones en pantalla")
        print("4. El sistema monitorear√° su nivel de ansiedad\n")
        
        input("Presione ENTER cuando est√© listo...")
        
        # Medir ansiedad inicial
        print("\nüìä Midiendo nivel de ansiedad inicial...")
        initial_anxiety = self._measure_current_anxiety(duration=10)
        print(f"Ansiedad inicial: {initial_anxiety:.1f}%")
        
        # Realizar 6 ciclos de respiraci√≥n
        num_cycles = 6
        for cycle in range(1, num_cycles + 1):
            print(f"\nüîÑ Ciclo {cycle}/{num_cycles}")
            self._breathing_cycle()
            
            # Medir ansiedad despu√©s de cada ciclo
            current_anxiety = self._measure_current_anxiety(duration=5)
            reduction = initial_anxiety - current_anxiety
            
            print(f"  Ansiedad actual: {current_anxiety:.1f}% "
                  f"(reducci√≥n: {reduction:.1f}%)")
            
            if reduction > 0:
                print(f"  ‚úì ¬°Bien! La ansiedad est√° bajando")
            
            time.sleep(2)  # Pausa entre ciclos
        
        # Medir ansiedad final
        print("\nüìä Midiendo nivel de ansiedad final...")
        final_anxiety = self._measure_current_anxiety(duration=10)
        total_reduction = initial_anxiety - final_anxiety
        reduction_percent = (total_reduction / initial_anxiety * 100) if initial_anxiety > 0 else 0
        
        # Resultados
        results = {
            'exercise': 'breathing_478',
            'initial_anxiety': initial_anxiety,
            'final_anxiety': final_anxiety,
            'reduction': total_reduction,
            'reduction_percent': reduction_percent,
            'num_cycles': num_cycles,
            'timeline': self.emotion_timeline,
            'timestamps': self.timestamps,
            'success': total_reduction > 0
        }
        
        # Mostrar resumen
        self._show_results(results)
        
        return results
    
    def _breathing_cycle(self):
        """Un ciclo completo de respiraci√≥n 4-7-8"""
        phases = [
            ('INHALE', 4, (0, 255, 0)),      # Verde - Inhalar 4 seg
            ('HOLD', 7, (255, 255, 0)),      # Amarillo - Retener 7 seg
            ('EXHALE', 8, (0, 100, 255))     # Naranja - Exhalar 8 seg
        ]
        
        for phase_name, duration, color in phases:
            start_time = time.time()
            
            while time.time() - start_time < duration:
                ret, frame = self.parent.camera.read()
                if not ret:
                    continue
                
                # Procesar emociones
                frame = self.parent.emotion_system.frame_processing(frame)
                
                # Calcular tiempo restante
                elapsed = time.time() - start_time
                remaining = duration - elapsed
                
                # Dibujar instrucciones grandes
                cv2.rectangle(frame, (0, 0), (frame.shape[1], 150), (0, 0, 0), -1)
                
                cv2.putText(frame, phase_name, 
                           (50, 80), cv2.FONT_HERSHEY_SIMPLEX, 
                           2.5, color, 4, cv2.LINE_AA)
                
                cv2.putText(frame, f"{remaining:.1f}s", 
                           (50, 130), cv2.FONT_HERSHEY_SIMPLEX, 
                           1.5, (255, 255, 255), 3, cv2.LINE_AA)
                
                # Barra de progreso
                progress = elapsed / duration
                bar_width = int(progress * (frame.shape[1] - 100))
                cv2.rectangle(frame, (50, 140), (50 + bar_width, 160), color, -1)
                cv2.rectangle(frame, (50, 140), (frame.shape[1] - 50, 160), (255, 255, 255), 2)
                
                cv2.imshow('Ejercicio de Respiracion', frame)
                cv2.waitKey(1)
    
    def _measure_current_anxiety(self, duration=10):
        """Mide nivel promedio de ansiedad durante X segundos"""
        anxiety_samples = []
        start_time = time.time()
        
        while time.time() - start_time < duration:
            ret, frame = self.parent.camera.read()
            if not ret:
                continue
            
            # Procesar frame
            frame = self.parent.emotion_system.frame_processing(frame)
            
            # Obtener nivel de miedo (proxy de ansiedad)
            # Nota: Necesitar√≠as acceder a las emociones del sistema
            # Aqu√≠ asumo que existe un m√©todo para obtenerlas
            try:
                emotions = self.parent.emotion_system.emotions_recognition.last_emotions
                anxiety = emotions.get('fear', 0)
                anxiety_samples.append(anxiety)
                
                # Guardar en timeline
                self.emotion_timeline.append(emotions.copy())
                self.timestamps.append(time.time())
            except:
                pass
            
            # Mostrar medici√≥n en progreso
            remaining = int(duration - (time.time() - start_time))
            cv2.putText(frame, f"Midiendo... {remaining}s", 
                       (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 
                       1, (255, 255, 0), 2)
            cv2.imshow('Ejercicio de Respiracion', frame)
            cv2.waitKey(1)
        
        return np.mean(anxiety_samples) if anxiety_samples else 0
    
    def _show_results(self, results):
        """Muestra resultados visuales del ejercicio"""
        cv2.destroyAllWindows()
        
        print("\n" + "=" * 60)
        print("RESULTADOS DEL EJERCICIO")
        print("=" * 60)
        print(f"\nüìä Ansiedad inicial: {results['initial_anxiety']:.1f}%")
        print(f"üìä Ansiedad final: {results['final_anxiety']:.1f}%")
        print(f"üìâ Reducci√≥n: {results['reduction']:.1f}% "
              f"({results['reduction_percent']:.1f}% de mejora)")
        
        if results['success']:
            print("\n‚úÖ ¬°√âXITO! El ejercicio redujo su ansiedad")
            if results['reduction_percent'] > 50:
                print("   ¬°Excelente resultado! Reducci√≥n mayor al 50%")
            elif results['reduction_percent'] > 30:
                print("   Buen resultado. Reducci√≥n significativa.")
            else:
                print("   Reducci√≥n moderada. Considere practicar m√°s.")
        else:
            print("\n‚ö†Ô∏è No se detect√≥ reducci√≥n de ansiedad")
            print("   Esto puede deberse a:")
            print("   - Necesita m√°s pr√°ctica con la t√©cnica")
            print("   - El nivel de ansiedad inicial era bajo")
            print("   - Factores externos interfirieron")
        
        # Crear gr√°fico de evoluci√≥n
        if len(results['timeline']) > 0:
            self._plot_anxiety_evolution(results)
    
    def _plot_anxiety_evolution(self, results):
        """Genera gr√°fico de evoluci√≥n de ansiedad"""
        fear_values = [e.get('fear', 0) for e in results['timeline']]
        time_points = [(t - results['timestamps'][0]) / 60 for t in results['timestamps']]
        
        plt.figure(figsize=(10, 6))
        plt.plot(time_points, fear_values, 'b-', linewidth=2, label='Nivel de Ansiedad')
        plt.axhline(y=results['initial_anxiety'], color='r', linestyle='--', 
                   label=f'Inicial: {results["initial_anxiety"]:.1f}%')
        plt.axhline(y=results['final_anxiety'], color='g', linestyle='--', 
                   label=f'Final: {results["final_anxiety"]:.1f}%')
        
        plt.xlabel('Tiempo (minutos)', fontsize=12)
        plt.ylabel('Nivel de Ansiedad (%)', fontsize=12)
        plt.title('Evoluci√≥n de Ansiedad Durante Ejercicio de Respiraci√≥n', 
                 fontsize=14, fontweight='bold')
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.ylim(0, 100)
        
        plt.tight_layout()
        plt.savefig(f'breathing_exercise_{datetime.now().strftime("%Y%m%d_%H%M%S")}.png')
        plt.show()
        
        print("\nüìà Gr√°fico guardado y mostrado")


class GroundingExercise54321:
    """
    T√©cnica de Grounding 5-4-3-2-1
    
    ¬øQu√© es?
    Ejercicio de atenci√≥n plena para crisis de ansiedad:
    - 5 cosas que puedes VER
    - 4 cosas que puedes TOCAR
    - 3 cosas que puedes O√çR
    - 2 cosas que puedes OLER
    - 1 cosa que puedes SABOREAR
    
    ¬øPara qu√© sirve?
    - Detener ataques de p√°nico
    - Desconexi√≥n de pensamientos ansiosos
    - Volver al momento presente
    - Reducir disociaci√≥n
    
    ¬øC√≥mo usa el biofeedback?
    - Monitorea reducci√≥n de ansiedad en cada paso
    - Confirma cuando el paciente se est√° calmando
    - Identifica qu√© sentidos son m√°s efectivos
    """
    def __init__(self, parent):
        self.parent = parent
        self.name = "Grounding 5-4-3-2-1"
        self.duration = 8
        self.indications = "Ataques de p√°nico, disociaci√≥n, ansiedad aguda"
        self.goal = "Reducir ansiedad y volver al presente"
    
    def run(self):
        """Ejecuta ejercicio de grounding con monitoreo"""
        print("=" * 60)
        print("EJERCICIO: GROUNDING 5-4-3-2-1")
        print("=" * 60)
        print("\nEste ejercicio le ayudar√° a conectar con el momento presente")
        print("usando sus cinco sentidos.\n")
        
        input("Presione ENTER para comenzar...")
        
        # Medir ansiedad inicial
        initial_anxiety = self._measure_anxiety(10)
        print(f"\nüìä Ansiedad inicial: {initial_anxiety:.1f}%")
        
        steps = [
            ("VISTA", 5, "Nombre 5 cosas que puede VER a su alrededor"),
            ("TACTO", 4, "Nombre 4 cosas que puede TOCAR"),
            ("O√çDO", 3, "Nombre 3 cosas que puede O√çR"),
            ("OLFATO", 2, "Nombre 2 cosas que puede OLER"),
            ("GUSTO", 1, "Nombre 1 cosa que puede SABOREAR")
        ]
        
        anxiety_per_step = [initial_anxiety]
        
        for sense, count, instruction in steps:
            print(f"\nüëâ {sense}: {instruction}")
            
            for i in range(1, count + 1):
                item = input(f"   {i}. ")
                print(f"      ‚úì {item}")
            
            # Medir ansiedad despu√©s de cada sentido
            current_anxiety = self._measure_anxiety(5)
            anxiety_per_step.append(current_anxiety)
            reduction = anxiety_per_step[-2] - current_anxiety
            
            print(f"\n   üìä Ansiedad: {current_anxiety:.1f}% "
                  f"(cambio: {reduction:+.1f}%)")
        
        # Resultados finales
        final_anxiety = anxiety_per_step[-1]
        total_reduction = initial_anxiety - final_anxiety
        
        results = {
            'exercise': 'grounding_54321',
            'initial_anxiety': initial_anxiety,
            'final_anxiety': final_anxiety,
            'reduction': total_reduction,
            'anxiety_per_step': anxiety_per_step,
            'success': total_reduction > 0
        }
        
        self._show_results(results)
        return results
    
    def _measure_anxiety(self, duration):
        """Mide ansiedad promedio"""
        # Similar a BreathingExercise478._measure_current_anxiety
        pass
    
    def _show_results(self, results):
        """Muestra resultados"""
        print("\n" + "=" * 60)
        print("RESULTADOS")
        print("=" * 60)
        print(f"\nüìä Reducci√≥n total: {results['reduction']:.1f}%")
        
        if results['success']:
            print("‚úÖ El ejercicio fue efectivo")
        else:
            print("‚ö†Ô∏è Considere repetir o probar otra t√©cnica")


# M√°s ejercicios: ProgressiveRelaxation, MindfulnessBodyScan, GradualExposureExercise
# Implementaci√≥n similar con monitoreo emocional espec√≠fico
```

#### üìù ¬øC√≥mo se usa?

```python
# Inicializar sistema con ejercicios
from therapy_tools.therapeutic_exercises import TherapeuticExercises
from examples.camera import Camera

camera = Camera(0, 1280, 720)
emotion_system = EmotionRecognitionSystem()
exercises = TherapeuticExercises(emotion_system, camera)

# Ver ejercicios disponibles
exercises.list_exercises()

# Ejecutar ejercicio de respiraci√≥n
results = exercises.start_exercise('breathing_478')

# Guardar resultados en base de datos
db.save_exercise_results(patient_id, results)

# El terapeuta puede revisar despu√©s qu√© ejercicios funcionan mejor
```

#### üéØ Valor terap√©utico

**Antes (sin biofeedback)**:
- Terapeuta: "Practique respiraci√≥n profunda cuando est√© ansioso"
- Paciente: "Lo intent√© pero no s√© si funciona"
- Resultado: Baja adherencia, dudas sobre efectividad

**Despu√©s (con biofeedback)**:
- Sistema: "Su ansiedad baj√≥ de 75% a 35% en 5 minutos"
- Paciente: "¬°Wow! Realmente funciona, lo vi en el gr√°fico"
- Resultado: Alta adherencia, confianza en la t√©cnica, pr√°ctica regular

---

## üìä M√©tricas Terap√©uticas Sugeridas

### M√©tricas por Sesi√≥n
- **Emoci√≥n dominante**: Emoci√≥n con mayor puntuaci√≥n promedio
- **Estabilidad emocional**: Varianza de emociones
- **Momentos cr√≠ticos**: Picos de emociones negativas
- **Tiempo de recuperaci√≥n**: Cu√°nto tarda en volver a neutral

### M√©tricas a Largo Plazo
- **Tendencia de bienestar**: Incremento de emociones positivas
- **Reducci√≥n de ansiedad**: Disminuci√≥n de miedo/preocupaci√≥n
- **Regulaci√≥n emocional**: Menor variabilidad entre sesiones
- **Resiliencia**: Recuperaci√≥n m√°s r√°pida de emociones negativas

---

## ‚ö†Ô∏è Consideraciones √âticas y Limitaciones

### Limitaciones T√©cnicas
1. **No es diagn√≥stico cl√≠nico**: Este sistema NO reemplaza evaluaci√≥n profesional
2. **Variabilidad individual**: Las expresiones faciales var√≠an entre culturas y personas
3. **Falsos positivos**: Puede confundir emociones similares (miedo vs. sorpresa)
4. **Condiciones de iluminaci√≥n**: Requiere buena iluminaci√≥n para precisi√≥n
5. **Expresiones microemocionales**: No detecta microexpresiones (<0.5 segundos)

### Consideraciones √âticas
1. **Consentimiento informado**: Siempre requerir autorizaci√≥n expl√≠cita
2. **Privacidad de datos**: Encriptar y proteger grabaciones
3. **No grabar sin permiso**: Cumplir con leyes de privacidad (GDPR, HIPAA)
4. **Uso complementario**: Herramienta de apoyo, no reemplazo del terapeuta
5. **Sesgo algor√≠tmico**: Puede tener menor precisi√≥n en ciertos grupos demogr√°ficos

### Recomendaciones de Uso
- ‚úÖ Como herramienta de biofeedback en sesi√≥n
- ‚úÖ Para entrenamiento en reconocimiento emocional
- ‚úÖ Para registro objetivo complementario
- ‚ùå NO como √∫nico m√©todo de evaluaci√≥n
- ‚ùå NO para decisiones cl√≠nicas cr√≠ticas sin supervisi√≥n
- ‚ùå NO sin consentimiento expl√≠cito del paciente

---

## üöÄ Roadmap para Versi√≥n Terap√©utica

### Fase 1: Fundamentos (2-4 semanas)
- [ ] Implementar base de datos de sesiones
- [ ] Crear sistema de perfiles de pacientes (anonimizados)
- [ ] Agregar exportaci√≥n de reportes PDF
- [ ] Implementar calibraci√≥n personal

### Fase 2: Funcionalidades Terap√©uticas (4-6 semanas)
- [ ] Dashboard de terapeuta con visualizaciones
- [ ] Sistema de ejercicios de regulaci√≥n emocional
- [ ] Modo de entrenamiento para reconocimiento emocional
- [ ] Alertas y sugerencias en tiempo real

### Fase 3: An√°lisis Avanzado (6-8 semanas)
- [ ] Machine Learning para patrones personalizados
- [ ] An√°lisis de correlaciones (eventos-emociones)
- [ ] Predicci√≥n de estados emocionales
- [ ] Integraci√≥n con wearables (frecuencia card√≠aca, etc.)

### Fase 4: Validaci√≥n Cl√≠nica (Ongoing)
- [ ] Estudios piloto con terapeutas
- [ ] Validaci√≥n con escalas cl√≠nicas est√°ndar
- [ ] Ajustes basados en feedback profesional
- [ ] Publicaci√≥n de resultados

---

## üìö Recursos Adicionales

### Teor√≠a de Emociones
- **Paul Ekman**: Emociones b√°sicas universales
- **Lisa Feldman Barrett**: Teor√≠a de emociones construidas
- **Modelo Circumplejo**: Valencia y activaci√≥n emocional

### Aplicaciones Cl√≠nicas
- **Terapia Cognitivo-Conductual (TCC)**: Registro de emociones
- **Terapia Dial√©ctico-Conductual (TDC)**: Regulaci√≥n emocional
- **Terapia de Exposici√≥n**: Monitoreo de ansiedad
- **Entrenamiento en Habilidades Sociales**: Reconocimiento emocional

### Tecnolog√≠as Relacionadas
- **Affectiva**: SDK comercial de reconocimiento emocional
- **Microsoft Emotion API**: Servicio cloud
- **OpenFace**: Toolkit acad√©mico de an√°lisis facial

---

## ü§ù Colaboraci√≥n con Profesionales

Para implementar este sistema en contexto terap√©utico real, se recomienda:

1. **Consultar con psic√≥logos cl√≠nicos** sobre necesidades espec√≠ficas
2. **Validar con estudios piloto** en entornos controlados
3. **Cumplir con regulaciones** de dispositivos m√©dicos si aplica
4. **Obtener certificaciones** de privacidad y seguridad de datos
5. **Capacitar a terapeutas** en interpretaci√≥n de resultados

---

## üìû Contacto y Contribuciones

Este an√°lisis fue creado para explorar el potencial terap√©utico del sistema.

**Para implementaci√≥n real en contexto cl√≠nico**:
- Consultar con comit√©s de √©tica
- Obtener aprobaciones institucionales
- Realizar pruebas de validaci√≥n
- Documentar limitaciones claramente

---

## üìÑ Licencia y Responsabilidad

‚ö†Ô∏è **IMPORTANTE**: Este sistema es una herramienta de investigaci√≥n y apoyo. NO es un dispositivo m√©dico certificado. El uso en contexto cl√≠nico debe ser supervisado por profesionales licenciados y cumplir con todas las regulaciones locales de salud mental y privacidad de datos.

---

**√öltima actualizaci√≥n**: Diciembre 2024
**Versi√≥n del an√°lisis**: 1.0
